{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68556ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, trace, function_tool, OpenAIChatCompletionsModel\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af26e788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df2eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "llma_api_key = os.getenv('LLAMA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4875089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "LLMA_BASE_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eaa091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_model_name = 'deepseek-chat'\n",
    "llma_model_name = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b1cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_client = AsyncOpenAI(\n",
    "    base_url = DEEPSEEK_BASE_URL, \n",
    "    api_key = deepseek_api_key\n",
    ")\n",
    "\n",
    "llma_client = AsyncOpenAI(\n",
    "    base_url = LLMA_BASE_URL,\n",
    "    api_key = llma_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200ad6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_model = OpenAIChatCompletionsModel(model=deepseek_model_name, openai_client=deepseek_client)\n",
    "llma_model = OpenAIChatCompletionsModel(model=llma_model_name, openai_client=llma_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f8fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions1 = \"You are witty sales agent for PKAI. You write professional and mindful emails\"\n",
    "instructions2 = \"You are humorous sales agent for PKAI. You write professional and likely to get response emails\"\n",
    "instructions3 = \"You are busy sales agent for PKAI. You write professional and concise emails\"\n",
    "agent1 = Agent(name=\"Agent 1\", instructions=instructions1, model=\"gpt-4o-mini\")\n",
    "agent2 = Agent(name=\"Agent 2\", instructions=instructions2, model=deepseek_model)\n",
    "agent3 = Agent(name=\"Agent 3\", instructions=instructions3, model=llma_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7767ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1_tool = agent1.as_tool(tool_name='agent_1_tool', tool_description='Write a cold email')\n",
    "agent2_tool = agent2.as_tool(tool_name='agent_2_tool', tool_description='Write a cold email')\n",
    "agent3_tool = agent3.as_tool(tool_name='agent_3_tool', tool_description='Write a cold email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb07c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email(subject:str, html_body:str) -> Dict[str, str]:\n",
    "    sg_client = sendgrid.SendGridAPIClient(api_key=os.getenv(\"SENDGRID_API_KEY\"))\n",
    "    from_email = Email(\"hello@priyanshukhandelwal.com\")\n",
    "    to_email = To(\"udemy@priyanshukhandelwal.com\")\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    response = sg_client.send(mail)\n",
    "    print(f\"Email sent with status code: {response.status_code}\")\n",
    "    return {'status':'success'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3201a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_writer_instructions = '''\n",
    "You are a subject writer for PKAI. You write professional and likely to get response subject based on the email content\n",
    "'''\n",
    "html_writer_instructions = \"You can convert a text email body to an HTML email body. \\\n",
    "You are given a text email body which might have some markdown \\\n",
    "and you need to convert it to an HTML email body with simple, clear, compelling layout and design.\"\n",
    "\n",
    "subject_writer_agent = Agent(name=\"Subject Writer\", instructions=subject_writer_instructions, model=\"gpt-4o-mini\")\n",
    "html_writer_agent = Agent(name=\"HTML Writer\", instructions=html_writer_instructions, model=\"gpt-4o-mini\")\n",
    "\n",
    "subject_writer_tool = subject_writer_agent.as_tool(tool_name='subject_writer_tool', tool_description='Write a subject')\n",
    "html_writer_tool = html_writer_agent.as_tool(tool_name='html_writer_tool', tool_description='Write an HTML email body')\n",
    "\n",
    "send_email_tool = send_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d61d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_tools = [ subject_writer_tool, html_writer_tool, send_email_tool]\n",
    "content_tools = [agent1_tool, agent2_tool, agent3_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8ca109",
   "metadata": {},
   "outputs": [],
   "source": [
    "emailer_instructions = '''\n",
    "You are an email formatter and sender. You receive the body of an email to be sent. \\\n",
    "You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. \\\n",
    "Finally, you use the send_html_email tool to send the email with the subject and HTML body.\n",
    "'''\n",
    "\n",
    "emailer_agent = Agent(name=\"Emailer\", \n",
    "                      instructions=emailer_instructions, \n",
    "                      model=\"gpt-4o-mini\",\n",
    "                      tools=email_tools, \n",
    "                      handoff_description=\"Convert email to html and send email\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0ba943",
   "metadata": {},
   "outputs": [],
   "source": [
    "handoffs_for_sales_manager = [emailer_agent] \n",
    "# now command goes to emailer agent, so if anything goes wrong we have to pick emailer agent for it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eba4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent with status code: 202\n"
     ]
    }
   ],
   "source": [
    "sales_manager_instructions = '''\n",
    "You are a salesmamager working for PKAI. You use the tools give to you to generate cold emails.\n",
    "You never generate sales emails by yourself; you always use tools.\n",
    "You try all 3 agent_tools once before choosing the best one. You can use tools iteratively untill you find a best email to send.\n",
    "You pick single best email using your own judgement of which email will be more effective.\n",
    "Then you handoff to EMAILER agent to send the email.\n",
    "'''\n",
    "\n",
    "sales_manager_agent = Agent(name = \"Sales Manager\",\n",
    "instructions = sales_manager_instructions,\n",
    "model = \"gpt-4o-mini\",\n",
    "tools = content_tools,\n",
    "handoffs = handoffs_for_sales_manager\n",
    ")\n",
    "\n",
    "with trace(\"Automated SDR\"):\n",
    "    response = await Runner.run(sales_manager_agent, \"Write and send a cold email to Dear Ceo of Legtis.com from Helena\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d5597",
   "metadata": {},
   "source": [
    "A guardrail in an AI agent context refers to safety mechanisms and constraints designed to ensure the agent operates within acceptable boundaries and behaves reliably. These are protective measures that prevent the agent from taking harmful, inappropriate, or unintended actions.\n",
    "Key types of guardrails include:\n",
    " - Input guardrails filter and validate what information or commands the agent receives, blocking malicious prompts, inappropriate content, or requests outside its intended scope.\n",
    " - Output guardrails monitor and filter the agent's responses before they're delivered, ensuring they don't contain harmful, biased, or inappropriate content.\n",
    " - Behavioral guardrails constrain the agent's decision-making process, preventing it from taking actions that could cause harm, violate policies, or exceed its authorized capabilities.\n",
    " - Resource guardrails limit the agent's access to systems, data, or computational resources, ensuring it can't overuse resources or access sensitive information it shouldn't.\n",
    " - Temporal guardrails implement timeouts, rate limits, and other time-based constraints to prevent runaway processes or excessive resource consumption.\n",
    " - Domain-specific guardrails restrict the agent to operate only within its intended domain or use case, preventing it from attempting tasks it's not designed for.\n",
    " \n",
    "These guardrails are essential for deploying AI agents in real-world applications where safety, reliability, and adherence to ethical guidelines are crucial. They help ensure that agents remain helpful while avoiding potential risks or unintended consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17480fa2",
   "metadata": {},
   "source": [
    "# OpenAI Agents SDK - Agent() Parameters Guide\n",
    "\n",
    "This is a comprehensive list of all parameters you can pass to the `Agent()` constructor in the OpenAI Agents Python SDK.\n",
    "\n",
    "## Core Parameters\n",
    "\n",
    "### `name` (str, required)\n",
    "- The name/identifier for the agent\n",
    "- Used for identification in logs and tracing\n",
    "\n",
    "### `instructions` (str or callable)\n",
    "- Also known as a developer message or system prompt\n",
    "- Can be a static string or a dynamic function that receives context and agent\n",
    "- For dynamic instructions: `def dynamic_instructions(context: RunContextWrapper[UserContext], agent: Agent[UserContext]) -> str`\n",
    "\n",
    "## Model Configuration\n",
    "\n",
    "### `model` (str or Model instance)\n",
    "- Which LLM to use\n",
    "- Can be a string like `\"o3-mini\"`, `\"gpt-4o\"`, etc.\n",
    "- Or a Model instance like `OpenAIChatCompletionsModel()`\n",
    "\n",
    "### `model_settings` (ModelSettings)\n",
    "- Optional model configuration parameters such as temperature\n",
    "- Configure temperature, top_p, max_tokens, tool_choice, etc.\n",
    "- Example: `ModelSettings(temperature=0.1, extra_args={\"service_tier\": \"flex\"})`\n",
    "\n",
    "## Tool and Capability Configuration\n",
    "\n",
    "### `tools` (list)\n",
    "- Tools that the agent can use to achieve its tasks\n",
    "- Can include function tools, hosted tools (WebSearchTool, FileSearchTool), etc.\n",
    "\n",
    "### `handoffs` (list)\n",
    "- Sub-agents that the agent can delegate to\n",
    "- List of other Agent instances for delegation/routing\n",
    "\n",
    "### `handoff_description` (str)\n",
    "- Provide additional context for determining handoff routing\n",
    "- Description used when this agent is a handoff target\n",
    "\n",
    "## Output Configuration\n",
    "\n",
    "### `output_type` (type)\n",
    "- If you want the agent to produce a particular type of output\n",
    "- Enables structured outputs using Pydantic models, dataclasses, TypedDict, etc.\n",
    "- When you pass an output_type, that tells the model to use structured outputs instead of regular plain text responses\n",
    "\n",
    "## Advanced Features\n",
    "\n",
    "### `hooks` (AgentHooks)\n",
    "- You can hook into the agent lifecycle with the hooks property\n",
    "- Subclass AgentHooks to observe agent lifecycle events\n",
    "\n",
    "### `input_guardrails` (list)\n",
    "- Guardrails allow you to run checks/validations on user input\n",
    "- List of input validation functions\n",
    "\n",
    "### `output_guardrails` (list)\n",
    "- Similar to input guardrails but for output validation\n",
    "\n",
    "## Behavior Configuration\n",
    "\n",
    "### `tool_use_behavior` (str)\n",
    "- If you want the Agent to completely stop after a tool call (rather than continuing with auto mode), you can set `Agent.tool_use_behavior=\"stop_on_first_tool\"`\n",
    "\n",
    "### `reset_tool_choice` (bool)\n",
    "- This behavior is configurable via agent.reset_tool_choice\n",
    "- Controls whether tool_choice resets to \"auto\" after tool calls\n",
    "\n",
    "## MCP Integration (if using MCP extension)\n",
    "\n",
    "### `mcp_servers` (list) - *Available with MCP extension*\n",
    "- Specify which MCP servers to use\n",
    "- List of MCP server names defined in configuration\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "from agents import Agent, ModelSettings, function_tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    result: str\n",
    "    confidence: float\n",
    "\n",
    "@function_tool\n",
    "def search_tool(query: str) -> str:\n",
    "    return f\"Results for {query}\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\"You are a helpful research assistant\",\n",
    "    model=\"gpt-4o\",\n",
    "    model_settings=ModelSettings(temperature=0.1),\n",
    "    tools=[search_tool],\n",
    "    output_type=OutputFormat,\n",
    "    handoff_description=\"Specialist for research tasks\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Quick Reference Table\n",
    "\n",
    "| Parameter | Type | Required | Description |\n",
    "|-----------|------|----------|-------------|\n",
    "| `name` | str | ✅ | Agent identifier |\n",
    "| `instructions` | str/callable | ✅ | System prompt/instructions |\n",
    "| `model` | str/Model | ❌ | LLM model to use |\n",
    "| `model_settings` | ModelSettings | ❌ | Model configuration |\n",
    "| `tools` | list | ❌ | Available tools |\n",
    "| `handoffs` | list | ❌ | Sub-agents for delegation |\n",
    "| `handoff_description` | str | ❌ | Description for routing |\n",
    "| `output_type` | type | ❌ | Structured output format |\n",
    "| `hooks` | AgentHooks | ❌ | Lifecycle event hooks |\n",
    "| `input_guardrails` | list | ❌ | Input validation |\n",
    "| `output_guardrails` | list | ❌ | Output validation |\n",
    "| `tool_use_behavior` | str | ❌ | Tool usage behavior |\n",
    "| `reset_tool_choice` | bool | ❌ | Tool choice reset behavior |\n",
    "| `mcp_servers` | list | ❌ | MCP servers (extension) |\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Parameters marked with ✅ are required\n",
    "- Parameters marked with ❌ are optional\n",
    "- The `mcp_servers` parameter is only available when using the MCP extension package\n",
    "- Dynamic instructions and guardrails support both sync and async functionsm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eab4f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding guardrails\n",
    "# from pydantic import BaseModel\n",
    "# class NameCheckOutput(BaseModel):\n",
    "#     is_name_in_message : bool\n",
    "#     name : str\n",
    "\n",
    "# guardrail_agent = Agent(\n",
    "#     name='Name-checker',\n",
    "#     instructions=\"Check if the user is including someone's personal name in what they want you to do.\",\n",
    "#     model = 'gpt-4o-mini',\n",
    "#     # tools= [],\n",
    "#     # handoffs = [],\n",
    "#     # handoff_description = '',\n",
    "#     output_type = NameCheckOutput\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaeb6bb",
   "metadata": {},
   "source": [
    "**What is ctx in this guardrail function?**\n",
    "ctx is a context object that:\n",
    "\n",
    "Contains execution state: It holds information about the current request, environment, and execution state\n",
    "Provides access to context information: Note how it's used in context=ctx.context to pass contextual information to the Runner.run function\n",
    "Is automatically injected: The framework automatically provides this parameter when your guardrail function is called\n",
    "\n",
    "**What does ctx typically contain?**\n",
    "While the exact contents depend on the framework you're using, a context object like ctx typically includes:\n",
    "\n",
    "Request metadata: Information about the current request\n",
    "Conversation history: Previous messages or interactions\n",
    "User information: Details about the user making the request (if authenticated)\n",
    "System state: Current state of the application or agent system\n",
    "Configuration settings: Runtime configuration that might affect guardrail behavior\n",
    "\n",
    "**How is ctx being used in your code?**\n",
    "In your specific example:\n",
    "\n",
    "ctx.context is being passed to Runner.run to provide the necessary context for the guardrail agent to properly evaluate the message\n",
    "This ensures the guardrail agent has access to the same contextual information as the main agent\n",
    "\n",
    "This pattern allows your guardrail to make informed decisions based not just on the current message, but potentially on the broader context of the conversation or application state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7233a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameCheckOutput(BaseModel):\n",
    "    is_name_in_message : bool\n",
    "    name : str\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name = 'Name-checker',\n",
    "    instructions = \"Check if the user is including someone's personal name in what they want you to do.\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    output_type = NameCheckOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930d801",
   "metadata": {},
   "source": [
    "# What is GuardrailFunctionOutput?\n",
    "GuardrailFunctionOutput is a structured return type specifically designed for guardrail functions. It serves as a standardized way to communicate the results of guardrail checks back to the system.\n",
    "Purpose of GuardrailFunctionOutput\n",
    "This class provides a consistent interface for guardrails to:\n",
    "\n",
    "Signal whether a tripwire was triggered: The tripwire_triggered parameter indicates if the guardrail detected a condition that requires intervention\n",
    "Return structured metadata: The output_info parameter allows passing additional information about what was detected\n",
    "Enable standardized handling: By using a consistent return type, the framework can process guardrail results uniformly\n",
    "\n",
    "Components of GuardrailFunctionOutput in Your Example\n",
    "In your specific implementation:\n",
    "\n",
    "tripwire_triggered:\n",
    "\n",
    "Set to the boolean value of is_name_in_message\n",
    "When True, signals that a personal name was detected in the message\n",
    "This likely affects how the system processes the message further\n",
    "\n",
    "\n",
    "output_info:\n",
    "\n",
    "Contains a dictionary with the key \"found_name\"\n",
    "Stores the full output from the guardrail agent (result.final_output)\n",
    "This may include additional details like the actual name found and its context\n",
    "\n",
    "\n",
    "\n",
    "How the System Uses GuardrailFunctionOutput\n",
    "When your guardrail function returns this object:\n",
    "\n",
    "If tripwire_triggered is True:\n",
    "\n",
    "The system may block the request\n",
    "It might request additional verification\n",
    "It could modify how the message is processed\n",
    "It might log the incident for review\n",
    "\n",
    "\n",
    "The output_info can be:\n",
    "\n",
    "Stored for audit purposes\n",
    "Used to provide specific feedback to users\n",
    "Passed to subsequent processing steps\n",
    "Used for analytics and guardrail improvement\n",
    "\n",
    "\n",
    "\n",
    "This standardized output structure enables a clean separation between detecting potentially problematic inputs and deciding how to handle them, giving the system flexibility in its response strategies.\n",
    "</artifact>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e5e1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import GuardrailFunctionOutput, input_guardrail\n",
    "\n",
    "@input_guardrail\n",
    "async def guardrail_against_name(ctx,agent, message):\n",
    "    result = await Runner.run(guardrail_agent, message, context=ctx.context)\n",
    "    is_name_in_message = result.final_output.is_name_in_message\n",
    "    print(is_name_in_message)\n",
    "    print(result.final_output.name)\n",
    "    return GuardrailFunctionOutput(output_info= {'Found Name' : result.final_output.name}, tripwire_triggered=is_name_in_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78f073f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "careful_sales_manager_agent = Agent(name = \"Sales Manager\",\n",
    "instructions = sales_manager_instructions,\n",
    "model = \"gpt-4o-mini\",\n",
    "tools = content_tools,\n",
    "handoffs = handoffs_for_sales_manager,\n",
    "input_guardrails = [guardrail_against_name]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "325a3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "CEO of Legtis.com\n",
      "Email sent with status code: 202\n"
     ]
    }
   ],
   "source": [
    "with trace(\"Protected SDK with guardrail for name\"):\n",
    "    result = await Runner.run(careful_sales_manager_agent, \"Write and send a cold email to Dear CEO of Legtis.com \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999a76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
